{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcastic News Headlines Detection using SVC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faisal-ai/Sarcastic-News-Headlines-Detection-Using-Support-Vector-Classifier/blob/main/Sarcastic_News_Headlines_Detection_using_SVC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwA9OqE1IY53"
      },
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Galut_WrI4bV"
      },
      "source": [
        "# training data\n",
        "train = pd.read_csv(\"/content/traind.csv\")\n",
        "\n",
        "# test data\n",
        "test = pd.read_csv(\"/content/testd.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvtCODUEJciM"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mni8YItfJcSs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "36ddf6a0-4c46-46f6-db00-b6f0af18ef7f"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic                                           headline\n",
              "0             1  thirtysomething scientists unveil doomsday clo...\n",
              "1             0  dem rep. totally nails why congress is falling...\n",
              "2             0  eat your veggies: 9 deliciously different recipes\n",
              "3             1  inclement weather prevents liar from getting t...\n",
              "4             1  mother comes pretty close to using word 'strea..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRex8owXJV40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "290491ec-2002-47bf-d8a9-0fa66301c045"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>bush proud u.s. economic woes can still depres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>chris pine depressed by realization he could p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>it's shark week!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>police found golden state killer by tracing ow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>virgin galactic is helping develop a new super...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic                                           headline\n",
              "0             1  bush proud u.s. economic woes can still depres...\n",
              "1             1  chris pine depressed by realization he could p...\n",
              "2             1                                   it's shark week!\n",
              "3             1  police found golden state killer by tracing ow...\n",
              "4             0  virgin galactic is helping develop a new super..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAUIxDOYJmvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a303441a-10dc-4238-9800-6f77ce6da7eb"
      },
      "source": [
        "#num of non-sarcastic headlines\n",
        "sum(train[\"is_sarcastic\"] == 0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11661"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijAyVcYjKPc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc70dab8-55b3-4e49-fd0a-3d5798022ac1"
      },
      "source": [
        "#num of sarcastic headlines\n",
        "sum(train[\"is_sarcastic\"] == 1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10636"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mubp2OU0M2-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159f2734-d849-44d0-97e0-082843959f33"
      },
      "source": [
        "# checking missing values\n",
        "train.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "is_sarcastic    0\n",
              "headline        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9uidliWUL9t"
      },
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9BW8zWhKWbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e201e36b-cb0f-4206-b336-3524522181ce"
      },
      "source": [
        "\n",
        "!pip install tweet-preprocessor"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB47T9w3YNry"
      },
      "source": [
        "# remove special characters using the regular expression library\n",
        "import re\n",
        "\n",
        "\n",
        "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
        "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kaf60xXPryT"
      },
      "source": [
        "import preprocessor as p\n",
        "\n",
        "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
        "def clean_tweets(df):\n",
        "  tempArr = []\n",
        "  for line in df:\n",
        "    # send to tweet_processor\n",
        "    tmpL = p.clean(line)\n",
        "    # remove puctuation\n",
        "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
        "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
        "    tempArr.append(tmpL)\n",
        "  return tempArr"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5BFI2HEUm6W"
      },
      "source": [
        "# clean training data\n",
        "train_headline = clean_tweets(train[\"headline\"])\n",
        "train_headline = pd.DataFrame(train_headline)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suq-CJYUXAT8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "6d76e724-4377-4ef1-8929-f88d60035d8b"
      },
      "source": [
        "# append cleaned headlines to the training data\n",
        "train[\"clean_headline\"] = train_headline\n",
        "\n",
        "# compare the cleaned and uncleaned headlines\n",
        "train.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>clean_headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>dem rep totally nails why congress is falling ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>eat your veggies deliciously different recipes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>mother comes pretty close to using word stream...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>my white inheritance</td>\n",
              "      <td>my white inheritance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>5 ways to file your taxes with less stress</td>\n",
              "      <td>ways to file your taxes with less stress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>richard branson's global-warming donation near...</td>\n",
              "      <td>richard bransons global warming donation nearl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>shadow government getting too large to meet in...</td>\n",
              "      <td>shadow government getting too large to meet in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>lots of parents know this scenario</td>\n",
              "      <td>lots of parents know this scenario</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                     clean_headline\n",
              "0             1  ...  thirtysomething scientists unveil doomsday clo...\n",
              "1             0  ...  dem rep totally nails why congress is falling ...\n",
              "2             0  ...     eat your veggies deliciously different recipes\n",
              "3             1  ...  inclement weather prevents liar from getting t...\n",
              "4             1  ...  mother comes pretty close to using word stream...\n",
              "5             0  ...                               my white inheritance\n",
              "6             0  ...           ways to file your taxes with less stress\n",
              "7             1  ...  richard bransons global warming donation nearl...\n",
              "8             1  ...  shadow government getting too large to meet in...\n",
              "9             0  ...                 lots of parents know this scenario\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_dHhhn2bHYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e5248240-cd0e-46ab-e25b-afa05e89b1d4"
      },
      "source": [
        "# cleaning the test data and appending the cleaned headlines to the test data\n",
        "test_headline = clean_tweets(test[\"headline\"])\n",
        "test_headline = pd.DataFrame(test_headline)\n",
        "\n",
        "test[\"clean_headline\"] = test_headline\n",
        "\n",
        "# compare the cleaned and uncleaned headlines\n",
        "test.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>clean_headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>bush proud u.s. economic woes can still depres...</td>\n",
              "      <td>bush proud us economic woes can still depress ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>chris pine depressed by realization he could p...</td>\n",
              "      <td>chris pine depressed by realization he could p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>it's shark week!</td>\n",
              "      <td>its shark week</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>police found golden state killer by tracing ow...</td>\n",
              "      <td>police found golden state killer by tracing ow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>virgin galactic is helping develop a new super...</td>\n",
              "      <td>virgin galactic is helping develop a new super...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                     clean_headline\n",
              "0             1  ...  bush proud us economic woes can still depress ...\n",
              "1             1  ...  chris pine depressed by realization he could p...\n",
              "2             1  ...                                     its shark week\n",
              "3             1  ...  police found golden state killer by tracing ow...\n",
              "4             0  ...  virgin galactic is helping develop a new super...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNJ7n2jXbzwl"
      },
      "source": [
        "# Test and Train split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQJjcE_Tb4JU"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = train.is_sarcastic.values\n",
        "\n",
        "# using 70% for the training and 30% for the testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(train.clean_headline.values, y, \n",
        "                                                   \n",
        "                                                    random_state=1, \n",
        "                                                    test_size=0.3, shuffle=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP0vIgrcdMSM"
      },
      "source": [
        "# Vectorize tweets using CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6M8mUI9n9fR"
      },
      "source": [
        "CountVectorizer Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reQP8v7Gb36g"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# vectorize tweets for model building\n",
        "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
        "\n",
        "# learn a vocabulary dictionary of all tokens in the raw documents\n",
        "vectorizer.fit(list(x_train) + list(x_test))\n",
        "\n",
        "# transform documents to document-term matrix\n",
        "x_train_vec = vectorizer.transform(x_train)\n",
        "x_test_vec = vectorizer.transform(x_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv02BKQ-ee_m"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it_BrO5qehpR"
      },
      "source": [
        "Classifying using Support Vetor Classifier (SVC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEXBqGBGeeG6"
      },
      "source": [
        "from sklearn import svm\n",
        "# classify using support vector classifier\n",
        "svm = svm.SVC(kernel = 'linear', probability=True)\n",
        "\n",
        "# fit the SVC model based on the given training data\n",
        "prob = svm.fit(x_train_vec, y_train).predict_proba(x_test_vec)\n",
        "\n",
        "# perform classification and prediction on samples in x_test\n",
        "y_pred_svm = svm.predict(x_test_vec)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SJ5l9iehjBT"
      },
      "source": [
        "# Accuracy score of the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lERS4fXwea7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29924f2-35bd-45e4-c0db-c71387022143"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy score for SVC is: \", accuracy_score(y_test, y_pred_svm) * 100, '%')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score for SVC is:  77.27952167414051 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}